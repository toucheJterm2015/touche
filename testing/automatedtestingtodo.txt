testing the automated system, we need:
- one new contest
- multiple sites
- multiple teams
- multiple problems
- sample submissions that get the proper response, in each language to demonstrate (that's 30 total submissions to produce. We can split it up somehow. Each take a language?)
 - Forbidden word (may omit for Java, or we could add a forbidden word for it for testing)
 - Undefined file type (should this be combined with wrong file type (like if someone submits a .txt) or would that be part of the Error: Reason Unknown category?)
 - Compile error (this is easiest. Delete semicolons!)
 - Exceeds time limit (infinite loop)
 - Incorrect Output (write an irrelevant program?)
 - Format Error (how would the automated system catch this?)
 - Runtime Error (can't think of how to deliberately cause this one, but I'm sure we'll stumble across something)
 - Other Error (Reason Unknown/unspecified)
 - proper output/accepted
shove this all into the database and fake timestamps (dbcreate.sql has examples of similar code to what we'll probably use)

We also need to make the way to "run" the contest based on the data we've just injected and I'm not really sure how to do that. It's the bigger part though.

